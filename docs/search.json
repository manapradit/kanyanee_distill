{
  "articles": [
    {
      "path": "about.html",
      "title": "About this site",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2022-12-28T17:38:12-05:00"
    },
    {
      "path": "index.html",
      "title": "Kanyanee's Projects",
      "description": "Welcome to the website. I hope you enjoy it!\n",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2022-12-28T17:38:13-05:00"
    },
    {
      "path": "virus_test_deep_learning.html",
      "title": "Virus Test",
      "description": "Knowledge Discovery and Data Mining Project",
      "author": [],
      "date": "4/20/2021",
      "contents": "\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nKanyanee's Projects\r\n\r\n\r\nHome\r\nAbout\r\nVirus\r\n☰\r\n\r\n\r\n  \r\n    \r\n      \r\n        \r\n        \r\n        \r\n      \r\n      \r\n    \r\n    \r\n      \r\n  Home\r\n\r\n\r\n  About\r\n\r\n\r\n  Virus\r\n\r\n      \r\n  \r\n\r\n\r\n\r\n\r\n\r\n\r\nVirus Test\r\n4/20/2021\r\n\r\n\r\n\r\n\r\n\r\nOverview\r\nData mining methods are widely used to identify patterns, rules or\r\nassociations, and to predict outcomes among numbers of data. The purpose\r\nof this project is to build a pipeline for periodic analysis of employee\r\nmedical data and choose the best classification technique. The employee\r\nmedical data is randomly generated with 6,781 observations. The process\r\nincludes merging the data, cleaning the data, processing classification\r\ntechnique, and generating plots. The decision tree was chosen for the\r\nfinal model due to its overall performance. The model is also easy to\r\nexplain and compare to other classification models.\r\n\r\n\r\nData\r\nThe employee medical data contains data from 6,781 employees in total\r\nwhich consists of 5,424 training data observations and 1,357 test data\r\nobservations. The data are from 2 sources, A and B, which consist of 6\r\nvariables and 8 variables, respectively. All files have an ID for each\r\nemployee which uniquely identifies the employee. Thus, employee ID 123\r\nin the A file is the same employee as ID 123 in the B file.\r\n\r\n\r\nData cleaning and preparation\r\nThis analysis utilizes the R markdown program along with multiple\r\nother R packages to do the model analysis. The following are R packages\r\nthat have been used in this analysis: ggplot2 and dplyr, accompanied\r\nwith a collection of R packages designed for data mining such as rpart,\r\nrpart.plot, e1071, neuralnet, and so on.\r\nTo clean and prepare the data for analysis, I read the dataset into R\r\nand merged the 2 source files horizontally by id and atRisk variables.\r\nThen, the data cleaning was performed to filter out observations with\r\nmissing data, noises, and outliers. I excluded the missing and noisy\r\nobservations due to the small number of mistakes and a concern about the\r\nuncertainty in filling in values. Each variable has a closer range to\r\nothers, so there might be other mistakes, not only the missing and noisy\r\nvalues. After filtering data inside the acceptable values, the outliers\r\nwere identified and removed if it is above the 75th or below the 25th\r\npercentile. Therefore, I decided to use only selected employees with\r\ncomplete data and omitted observations with missing (n=8), noisy (n=11),\r\nor outlier values (n=239), which resulted in dropping 259 observations\r\nfrom the training data. In addition, some data types had to be changed\r\nfrom numeric to categorical and adjusted for the appropriate usage.\r\n# read data into R\r\ndataTrainA=read.table(\"data/virus_test_deep_learning/dataTrainA.txt\", header=TRUE)\r\ndataTrainB=read.table(\"data/virus_test_deep_learning/dataTrainB.txt\", header=TRUE)\r\ndataTestA=read.table(\"data/virus_test_deep_learning/dataTestA.txt\", header=TRUE)\r\ndataTestB=read.table(\"data/virus_test_deep_learning/dataTestB.txt\", header=TRUE)\r\n\r\n# Merge train dataset A and B by id and atRisk\r\ntraindata=merge(dataTrainA, dataTrainB, by=c(\"id\",\"atRisk\"))\r\n\r\n# Merge test dataset A and B\r\ntestdata=merge(dataTestA, dataTestB, by=c(\"id\",\"atRisk\"))\r\nThe train data has 8 missing values, while the test data has no\r\nmissing value.\r\ntable(is.na(traindata))\r\n## \r\n## FALSE  TRUE \r\n## 65080     8\r\ntable(is.na(testdata))\r\n## \r\n## FALSE \r\n## 16284\r\n#functions to filter noises and missing\r\nmyCleanFunction <- function(datatoclean){\r\n                    datatoclean%>%filter(between(temp,90,106),\r\n                      between(bpSys,97,150),\r\n                      between(vo2,10,70),\r\n                      between(throat,80,120),\r\n                      between(atRisk,0,1),\r\n                      between(headA,0,9),\r\n                      between(bodyA,0,9),\r\n                      between(cough,0,1),\r\n                      between(runny,0,1),\r\n                      between(nausea,0,1),\r\n                      between(diarrhea,0,1)\r\n                    )} \r\n\r\n#function to identify outliers\r\noutliers <- function(data,c){boxplot(data[,c], plot=FALSE)$out}\r\nTrain and test data after cleaning Train\r\ndata\r\nsummary(tr)\r\n##        id           atRisk            temp            bpSys      \r\n##  Min.   :   0   Min.   :0.0000   Min.   : 96.18   Min.   :103.0  \r\n##  1st Qu.:1688   1st Qu.:0.0000   1st Qu.: 97.77   1st Qu.:119.0  \r\n##  Median :3360   Median :0.0000   Median : 98.16   Median :124.0  \r\n##  Mean   :3383   Mean   :0.4521   Mean   : 98.40   Mean   :124.4  \r\n##  3rd Qu.:5091   3rd Qu.:1.0000   3rd Qu.: 98.80   3rd Qu.:130.0  \r\n##  Max.   :6780   Max.   :1.0000   Max.   :100.63   Max.   :146.0  \r\n##       vo2            throat          headA           bodyA      \r\n##  Min.   :22.00   Min.   : 88.0   Min.   :0.000   Min.   :1.000  \r\n##  1st Qu.:34.00   1st Qu.: 97.0   1st Qu.:3.000   1st Qu.:4.000  \r\n##  Median :39.00   Median :100.0   Median :3.000   Median :4.000  \r\n##  Mean   :38.04   Mean   :100.1   Mean   :3.451   Mean   :4.017  \r\n##  3rd Qu.:42.00   3rd Qu.:103.0   3rd Qu.:4.000   3rd Qu.:4.000  \r\n##  Max.   :54.00   Max.   :112.0   Max.   :8.000   Max.   :7.000  \r\n##      cough            runny            nausea          diarrhea     \r\n##  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \r\n##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \r\n##  Median :0.0000   Median :0.0000   Median :0.0000   Median :0.0000  \r\n##  Mean   :0.3258   Mean   :0.1983   Mean   :0.2403   Mean   :0.1022  \r\n##  3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.0000  \r\n##  Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000\r\nTest data\r\nsummary(te)\r\n##        id           atRisk            temp            bpSys      \r\n##  Min.   :   2   Min.   :0.0000   Min.   : 96.35   Min.   : 98.0  \r\n##  1st Qu.:1786   1st Qu.:0.0000   1st Qu.: 97.79   1st Qu.:119.0  \r\n##  Median :3533   Median :0.0000   Median : 98.21   Median :124.0  \r\n##  Mean   :3447   Mean   :0.4584   Mean   : 98.51   Mean   :124.4  \r\n##  3rd Qu.:5087   3rd Qu.:1.0000   3rd Qu.: 99.12   3rd Qu.:130.0  \r\n##  Max.   :6770   Max.   :1.0000   Max.   :101.58   Max.   :147.0  \r\n##       vo2            throat           headA           bodyA      \r\n##  Min.   :18.00   Min.   : 86.00   Min.   :0.000   Min.   :2.000  \r\n##  1st Qu.:33.00   1st Qu.: 97.00   1st Qu.:3.000   1st Qu.:4.000  \r\n##  Median :38.00   Median :100.00   Median :3.000   Median :4.000  \r\n##  Mean   :37.48   Mean   : 99.73   Mean   :3.408   Mean   :4.025  \r\n##  3rd Qu.:42.00   3rd Qu.:103.00   3rd Qu.:4.000   3rd Qu.:4.000  \r\n##  Max.   :55.00   Max.   :114.00   Max.   :8.000   Max.   :7.000  \r\n##      cough          runny            nausea          diarrhea      \r\n##  Min.   :0.00   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000  \r\n##  1st Qu.:0.00   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000  \r\n##  Median :0.00   Median :0.0000   Median :0.0000   Median :0.00000  \r\n##  Mean   :0.35   Mean   :0.1945   Mean   :0.2402   Mean   :0.09359  \r\n##  3rd Qu.:1.00   3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.00000  \r\n##  Max.   :1.00   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000\r\n\r\n\r\nExploratory Data Analysis\r\nThe exploratory data analysis was performed to develop an\r\nunderstanding of the data, and the table below shows a glance summary of\r\neach variable. There are 5 numeric variables such as patient’s\r\ntemperature (temp), blood pressure (systolic) (bpSys), VO2 max (vo2),\r\nand throat culture (throat). There are 6 categorical variables including\r\nlevel of headache, level of body ache, cough, runny nose, nausea,\r\ndiarrhea, and virus test (atRisk).\r\nTable 1: Table representing variable summary (n=5165).\r\nVariable\r\nType\r\nMedian\r\nMean\r\nSD\r\nMin\r\nMax\r\ntemp\r\nNumeric\r\n98.16\r\n98.4\r\n0.91\r\n96.18\r\n100.63\r\nbpSys\r\nNumeric\r\n124\r\n124.4\r\n8.05\r\n103\r\n146\r\nvo2\r\nNumeric\r\n39\r\n38.04\r\n5.97\r\n22\r\n54\r\nthroat\r\nNumeric\r\n100\r\n100.1\r\n4.47\r\n88\r\n112\r\nheadA\r\nFactor\r\n3\r\n3.45\r\n1.07\r\n0\r\n8\r\nbodyA\r\nFactor\r\n4\r\n4.02\r\n0.67\r\n1\r\n7\r\ncough\r\nFactor\r\n0 (n=3482), 1 (n=1683)\r\n\r\n\r\n\r\n\r\nrunny\r\nFactor\r\n0 (n=4141), 1 (n=1024)\r\n\r\n\r\n\r\n\r\nnausea\r\nFactor\r\n0 (n=3924), 1 (n=1241)\r\n\r\n\r\n\r\n\r\ndiarrhea\r\nFactor\r\n0 (n=4637), 1 (n=528)\r\n\r\n\r\n\r\n\r\natRisk\r\nFactor\r\n0 (n=2830), 1 (n=2335)\r\n\r\n\r\n\r\n\r\n\r\nHistogram\r\nhist2 = function(df, var,b){ggplot(df, aes(x=var, color=atRisk))+\r\n    geom_histogram(fill=\"white\", alpha=0.5, position=\"identity\",binwidth = b)+\r\n    theme_minimal()+\r\n    ggtitle(\"Histogram of employee medical data\")}\r\n\r\n\r\n\r\nBoxplot\r\nboxplotFunction=function(dat,c,var, title, x, y){\r\n  boxplot(dat[,c]~var, data=dat, main=title,\r\n          xlab=x, ylab=y)}\r\n\r\nOverall, the distributions vary, but histograms positive and negative\r\nvirus tests show that there is normal distribution for all the variables\r\nexcept for the patient’s temperature. The histogram that displays the\r\ntemperature variable is a bi-modal distribution with a higher frequency\r\non the left distribution. The histogram of the temperature variable by\r\nthe virus test illustrates that the distribution of the negative test\r\ngroup is skewed to the right, while the positive test group is bi-modal.\r\nThis could be because some people who had the virus are symptomatic or\r\nthe data was collected during the incubation period. In addition, the\r\nboxplot of throat culture for positive and negative virus tests has two\r\nsimilar shapes, so we can expect this variable to have an insignificant\r\nimpact in this analysis.\r\n\r\n\r\n\r\nModels\r\nThe algorithms used to build the model include decision tree (CART),\r\nNaive Bayes, support vector machine (SVM), and neural networks (ANN).\r\nAll were implemented in R. The simplest form for each classifier was\r\nused and parameters were set; for SVM, kernel=polynomial and for ANN,\r\nhidden=4. Each model had been divided into four steps. First, prepare\r\nthe data to use in the model as different models have preferred types of\r\ndata; for example, ANN model requires numeric data. Second, the model\r\nwas built from the training data, followed by predicting the outcome\r\nusing test data. Finally, the accuracy of each model was calculated so I\r\ncould compare the models’ performance.\r\n\r\nTree model\r\nThe tree is build using this equation;\r\natRisk~temp+bpSys+vo2+throat+headA+bodyA+cough+runny+nausea+diarrhea\r\neq=atRisk~temp+bpSys+vo2+throat+headA+bodyA+cough+runny+nausea+diarrhea #equation for models\r\n# 1. Prepare Data\r\ntr_tree=tr\r\nte_tree=te\r\n\r\ntr_tree[,2]=as.factor(tr_tree[,2])\r\nfor (i in 7:12){tr_tree[,i] = as.factor(tr_tree[,i])}\r\n\r\nte_tree[,2]=as.factor(te_tree[,2])\r\nfor (i in 7:12){te_tree[,i] = as.factor(te_tree[,i])}\r\n\r\n# 2. Build Model\r\n# use rpart to build a decision tree model using atRisk as the class and all of the attributes except id\r\nt1=Sys.time()\r\nmod_tree=rpart(eq, data=tr_tree)\r\nt2=Sys.time()\r\ntime_treel = as.double(t2-t1)\r\nmod_tree\r\n## n= 5165 \r\n## \r\n## node), split, n, loss, yval, (yprob)\r\n##       * denotes terminal node\r\n## \r\n##  1) root 5165 2335 0 (0.5479187 0.4520813)  \r\n##    2) bpSys< 126.5 3105  836 0 (0.7307568 0.2692432)  \r\n##      4) temp< 99.165 2812  584 0 (0.7923186 0.2076814)  \r\n##        8) headA=0,1,2,3,4 2486  335 0 (0.8652454 0.1347546) *\r\n##        9) headA=5,6,7 326   77 1 (0.2361963 0.7638037) *\r\n##      5) temp>=99.165 293   41 1 (0.1399317 0.8600683) *\r\n##    3) bpSys>=126.5 2060  561 1 (0.2723301 0.7276699)  \r\n##      6) temp< 99.125 1303  482 1 (0.3699156 0.6300844)  \r\n##       12) headA=1,2,3 440   86 0 (0.8045455 0.1954545) *\r\n##       13) headA=4,5,6,7,8 863  128 1 (0.1483198 0.8516802) *\r\n##      7) temp>=99.125 757   79 1 (0.1043593 0.8956407) *\r\n#plot the decision tree using rpart.plot\r\nrpart.plot(mod_tree)\r\n\r\n#What is one of the main determiners of voter approval?\r\n\r\n# 3. Predict\r\nt1=Sys.time()\r\npred_tree = predict(mod_tree, te_tree[c(3,4,5,6,7,8,9,10,11,12)], type=\"vector\")\r\nt2=Sys.time()\r\ntime_treep = as.double(t2-t1)\r\n\r\n# 4. Calculate accuracy\r\ntab_tree = table(te_tree$atRisk,pred_tree)\r\ntab_tree\r\n##    pred_tree\r\n##       1   2\r\n##   0 630 105\r\n##   1 101 521\r\naccFunction=function(table){sum(diag(table))/sum(table)}\r\n#acc_tree <- sum(diag(tab1))/sum(tab1)\r\nacc_tree=accFunction(tab_tree)\r\nacc_tree\r\n## [1] 0.8481945\r\n\r\nPruning the tree\r\ntrain=tr_tree\r\n\r\n#Base Model\r\nbase_model <- rpart(eq, data = train, method = \"class\",\r\n                       control = rpart.control(cp = 0))\r\n#summary(base_model)\r\n\r\n#Plot Decision Tree\r\nplot(base_model)\r\n\r\n# Examine the complexity plot\r\nprintcp(base_model)\r\n## \r\n## Classification tree:\r\n## rpart(formula = eq, data = train, method = \"class\", control = rpart.control(cp = 0))\r\n## \r\n## Variables actually used in tree construction:\r\n## [1] bodyA  bpSys  headA  nausea runny  temp   throat vo2   \r\n## \r\n## Root node error: 2335/5165 = 0.45208\r\n## \r\n## n= 5165 \r\n## \r\n##            CP nsplit rel error  xerror     xstd\r\n## 1  4.0171e-01      0   1.00000 1.00000 0.015318\r\n## 2  9.0364e-02      1   0.59829 0.61542 0.013793\r\n## 3  7.3662e-02      2   0.50792 0.52934 0.013132\r\n## 4  5.7388e-02      3   0.43426 0.41842 0.012054\r\n## 5  3.8544e-03      5   0.31949 0.32634 0.010915\r\n## 6  2.9979e-03      7   0.31178 0.31777 0.010795\r\n## 7  2.8551e-03     10   0.30278 0.31306 0.010728\r\n## 8  1.7131e-03     13   0.29422 0.30621 0.010629\r\n## 9  1.2848e-03     15   0.29079 0.31049 0.010691\r\n## 10 6.4240e-04     20   0.28394 0.30278 0.010579\r\n## 11 4.2827e-04     22   0.28266 0.30835 0.010661\r\n## 12 2.5696e-04     28   0.28009 0.31263 0.010722\r\n## 13 2.1413e-04     34   0.27837 0.32120 0.010844\r\n## 14 1.6472e-04     42   0.27666 0.32291 0.010868\r\n## 15 1.0707e-04     55   0.27452 0.33191 0.010992\r\n## 16 9.5170e-05     59   0.27409 0.33490 0.011032\r\n## 17 7.1378e-05     68   0.27323 0.34133 0.011119\r\n## 18 6.1181e-05     74   0.27281 0.34604 0.011181\r\n## 19 0.0000e+00     81   0.27238 0.35032 0.011237\r\nplotcp(base_model)\r\n\r\nrpart.plot(base_model)\r\n\r\ntest=te_tree\r\n\r\n# Compute the accuracy of the pruned tree\r\ntest$pred <- predict(base_model, te_tree[c(3,4,5,6,7,8,9,10,11,12)], type = \"class\")\r\nbase_accuracy <- mean(test$pred == test$atRisk)\r\n# Grow a tree with minsplit of 100 and max depth of 8\r\nmodel_preprun <- rpart(eq, data = train, method = \"class\", \r\n                   control = rpart.control(cp = 0, maxdepth = 8,minsplit = 100))\r\n# Compute the accuracy of the pruned tree\r\ntest$pred <- predict(model_preprun, te_tree[c(3,4,5,6,7,8,9,10,11,12)], type = \"class\")\r\naccuracy_preprun <- mean(test$pred == test$atRisk)\r\n\r\nrpart.plot(model_preprun)\r\n\r\n#Postpruning\r\n# Prune the base_model based on the optimal cp value\r\nmodel_pruned <- prune(base_model, cp = 0.0084 )\r\n\r\n# Compute the accuracy of the pruned tree\r\ntest$pred <- predict(model_pruned, te_tree[c(3,4,5,6,7,8,9,10,11,12)], type = \"class\")\r\naccuracy_postprun <- mean(test$pred == test$atRisk)\r\ndata.frame(base_accuracy, accuracy_preprun, accuracy_postprun)\r\n##   base_accuracy accuracy_preprun accuracy_postprun\r\n## 1     0.8327192        0.8607222         0.8481945\r\nrpart.plot(model_pruned)\r\n\r\n\r\n\r\n\r\nNaive Bayes Model\r\n# 1. Prepare Data\r\n#https://www.rdocumentation.org/packages/e1071/versions/1.7-6/topics/naiveBayes\r\n#library(e1071)\r\ntr_nb=tr\r\nte_nb=te\r\n\r\ntr_nb[,2]=as.factor(tr_nb[,2])\r\nfor (i in 7:12){tr_nb[,i] = as.factor(tr_nb[,i])}\r\n\r\nte_nb[,2]=as.factor(te_nb[,2])\r\nfor (i in 7:12){te_nb[,i] = as.factor(te_nb[,i])}\r\n\r\n# 2. Build Model\r\nt1=Sys.time()\r\nmod_nb=naiveBayes(eq,tr_nb)\r\nt2=Sys.time()\r\ntime_nbl = as.double(t2-t1)\r\nmod_nb\r\n## \r\n## Naive Bayes Classifier for Discrete Predictors\r\n## \r\n## Call:\r\n## naiveBayes.default(x = X, y = Y, laplace = laplace)\r\n## \r\n## A-priori probabilities:\r\n## Y\r\n##         0         1 \r\n## 0.5479187 0.4520813 \r\n## \r\n## Conditional probabilities:\r\n##    temp\r\n## Y       [,1]      [,2]\r\n##   0 98.08185 0.6109729\r\n##   1 98.78294 1.0465964\r\n## \r\n##    bpSys\r\n## Y       [,1]     [,2]\r\n##   0 120.8972 6.879693\r\n##   1 128.6039 7.299815\r\n## \r\n##    vo2\r\n## Y       [,1]     [,2]\r\n##   0 39.64346 4.897654\r\n##   1 36.08651 6.552161\r\n## \r\n##    throat\r\n## Y       [,1]     [,2]\r\n##   0 100.0049 4.499163\r\n##   1 100.1118 4.432094\r\n## \r\n##    headA\r\n## Y              0            1            2            3            4\r\n##   0 0.0007067138 0.0215547703 0.1236749117 0.6742049470 0.1257950530\r\n##   1 0.0004282655 0.0115631692 0.0745182013 0.3811563169 0.1379014989\r\n##    headA\r\n## Y              5            6            7            8\r\n##   0 0.0445229682 0.0084805654 0.0010600707 0.0000000000\r\n##   1 0.3250535332 0.0612419700 0.0077087794 0.0004282655\r\n## \r\n##    bodyA\r\n## Y              1            2            3            4            5\r\n##   0 0.0007067138 0.0166077739 0.1293286219 0.6826855124 0.1424028269\r\n##   1 0.0017130621 0.0175588865 0.1336188437 0.6959314775 0.1366167024\r\n##    bodyA\r\n## Y              6            7\r\n##   0 0.0257950530 0.0024734982\r\n##   1 0.0137044968 0.0008565310\r\n## \r\n##    cough\r\n## Y           0         1\r\n##   0 0.7720848 0.2279152\r\n##   1 0.5554604 0.4445396\r\n## \r\n##    runny\r\n## Y           0         1\r\n##   0 0.8053004 0.1946996\r\n##   1 0.7974304 0.2025696\r\n## \r\n##    nausea\r\n## Y           0         1\r\n##   0 0.8710247 0.1289753\r\n##   1 0.6248394 0.3751606\r\n## \r\n##    diarrhea\r\n## Y            0          1\r\n##   0 0.89328622 0.10671378\r\n##   1 0.90321199 0.09678801\r\n# 3. Predict\r\nt1=Sys.time()\r\npred_nb = predict(mod_nb, te_nb[c(3,4,5,6,7,8,9,10,11)])\r\nt2=Sys.time()\r\ntime_nbp = as.double(t2-t1)\r\n\r\n# 4. Calculate accuracy\r\ntab_nb=table(pred_nb,te_nb$atRisk)\r\ntab_nb\r\n##        \r\n## pred_nb   0   1\r\n##       0 639 109\r\n##       1  96 513\r\nacc_nb =accFunction(tab_nb)\r\nacc_nb\r\n## [1] 0.8489315\r\n\r\n\r\nSVM Model\r\n# 1. Prepare Data\r\n#http://uc-r.github.io/svm\r\n#https://www.rdocumentation.org/packages/e1071/versions/1.7-6/topics/plot.svm\r\n#For svm you will have to make them all numeric (integer) except the class.\r\ntr_svm=tr[-c(1)]\r\nte_svm=te[-c(1)]\r\n\r\ntrainsvmdata <- as.data.frame(apply(tr_svm, 2, as.integer)) #make all numeric\r\ntrainsvmdata[,1]=as.factor(tr_svm[,1])   #except class is a factor\r\n\r\ntestsvmdata <- as.data.frame(apply(te_svm, 2, as.integer)) #make all numeric\r\ntestsvmdata[,1]=as.factor(te_svm[,1])   #except class is a factor\r\n\r\n# 2. Build Model\r\n#SVM model 1 linear not working as line cannot divide between atRisk.\r\nt1=Sys.time()\r\nmod_svm1=svm(eq, data=trainsvmdata, kernel=\"linear\")\r\nt2=Sys.time()\r\ntime_svmll = as.double(t2-t1)\r\nmod_svm1\r\n## \r\n## Call:\r\n## svm(formula = eq, data = trainsvmdata, kernel = \"linear\")\r\n## \r\n## \r\n## Parameters:\r\n##    SVM-Type:  C-classification \r\n##  SVM-Kernel:  linear \r\n##        cost:  1 \r\n## \r\n## Number of Support Vectors:  2200\r\n# 3. Predict\r\nt1=Sys.time()\r\npredsvm1 = predict(mod_svm1,testsvmdata[c(2,3,4,5,6,7,8,9,10,11)])\r\nt2=Sys.time()\r\ntime_svmlp = as.double(t2-t1)\r\n\r\n# 4. Calculate accuracy\r\ntab_svmlin=table(predsvm1,testsvmdata$atRisk)\r\ntab_svmlin\r\n##         \r\n## predsvm1   0   1\r\n##        0 632 114\r\n##        1 103 508\r\nacc_svm1=accFunction(tab_svmlin)\r\nacc_svm1\r\n## [1] 0.8400884\r\n# 2.2 Build Model SVM with  kernel=\"polynomial\"\r\n#SVM model 2\r\nt1=Sys.time()\r\nmod_svm2=svm(eq, data=trainsvmdata, kernel=\"polynomial\")\r\nt2=Sys.time()\r\ntime_svmpl = as.double(t2-t1)\r\nmod_svm2\r\n## \r\n## Call:\r\n## svm(formula = eq, data = trainsvmdata, kernel = \"polynomial\")\r\n## \r\n## \r\n## Parameters:\r\n##    SVM-Type:  C-classification \r\n##  SVM-Kernel:  polynomial \r\n##        cost:  1 \r\n##      degree:  3 \r\n##      coef.0:  0 \r\n## \r\n## Number of Support Vectors:  2128\r\n# 3.2 Predict\r\nt1=Sys.time()\r\npredsvm2 = predict(mod_svm2,testsvmdata[c(2,3,4,5,6,7,8,9,10,11)])\r\nt2=Sys.time()\r\ntime_svmpp = as.double(t2-t1)\r\n\r\n# 4.2 Calculate accuracy\r\ntab_svm2=table(predsvm2,testsvmdata$atRisk)\r\ntab_svm2\r\n##         \r\n## predsvm2   0   1\r\n##        0 656 128\r\n##        1  79 494\r\nacc_svm2=accFunction(tab_svm2)\r\nacc_svm2\r\n## [1] 0.8474576\r\n\r\n\r\nANN\r\n\r\n\r\n\r\nModel Selection\r\nAfter running the models in R markdown which is provided in the\r\nappendix, we obtain the following results as shown in table 2 below. ANN\r\nhas the highest accuracy among these classifications at 0.862, followed\r\nby Naive Bayes, decision tree, and support vector machine (SVM) with\r\naccuracy rates of 0.849, 0.848, and 0.847, respectively. Unsurprisingly,\r\nANN is the most accurate in this analysis because ANN is more complex\r\nthan other models. This is also because this analysis set the hidden\r\nnodes equal to 4, but the accuracy decreases to almost the same as other\r\ntechniques when using hidden nodes equal to 3.\r\nThen, I used learning time and predicting time to compare the model\r\nexpensiveness. The learning time is the time that the model spends on\r\ntraining the model. The predicting time is the time that the model uses\r\nto predict the class of the test dataset. The decision tree has the\r\nleast predicting time at 5.00 seconds, with second lowest learning time\r\nat 1.02 seconds. Although, Naive Bayes has the least learning time at\r\n0.78 seconds, it has high predicting time at 16.46 seconds.\r\nUnfortunately, ANN’s learning time is extremely high (32 minutes)\r\nbecause the high accuracy of ANN is compensated by the time that ANN\r\nspends learning the complex model.\r\nAccording to the small difference in accuracy and the model\r\nexpensiveness, I decided to use the decision tree technique for further\r\nanalysis. Even though the tree has limitations over accuracy and\r\nlearning time in this test, there are advantages compared to other\r\ntechniques. The decision tree model is easy to understand and interpret\r\nwith simple visualization, which allows quick prediction using the\r\ncondition in the tree diagram. Decision tree can handle collinearity\r\nefficiently. It is less complex than ANN and SVM but still flexible than\r\nNaive Bayes.\r\nTable 2: Table representing the model’s effectiveness using training\r\ndata = 5,165 and test data = 1,357\r\nModel\r\nAccuracy\r\nLearning Time (minute)\r\nPredicting Time (Munite)\r\nTree\r\n0.8482\r\n0.08329\r\n0.017\r\nNaive Bayes\r\n0.84893\r\n0.01296\r\n0.27427\r\nSVM\r\n0.84746\r\n1.15642\r\n0.0728\r\nANN\r\n0.8622\r\n32.02853\r\n0.01596\r\nNote: Best performance in Bold\r\n\r\n\r\nFinal Model\r\nI chose decision tree for the final model because of its overall\r\nperformance, and the model is easy to understand by people. In addition,\r\npruning technique was performed to compare the tree performance of the\r\nbase model, the model before pruning, and the model after pruning. The\r\npruning process involves removing the branches that make use of features\r\nhaving low importance. This reduces the complexity of the tree, hence\r\nincreasing its predictive power by reducing overfitting. The type of\r\ndecision tree used in this analysis is Classification And Regression\r\nTree (CART) which shows both prediction outcomes, discrete number of\r\nclass and a real number of predicted outcome. The colored leaves show\r\nthe probability of virus test status, and the percentage represents the\r\nnumber of employees in the train data that belong to the group. The bold\r\ntext in black represents a condition based on which the tree splits into\r\nyes or no.\r\nThe tree diagram used 3 variables for prediction including blood\r\npressure, temperature, and headache level. The model suggested that an\r\nemployee with a temperature of more than 99.1 degree Fahrenheit is very\r\nlikely to have the virus. An employee is also likely to have the virus\r\nif the employee has blood pressure more than 127, temperature less than\r\n99° Fahrenheit, and has the headache level of more than 4. Likewise, an\r\nemployee with lower blood pressure and temperature with the level of\r\nheadache below 4 is likely to have a negative virus test.\r\nI think that these 3 variables and conditions used in the tree\r\ndiagram makes sense. First, blood pleasure is the most predictive\r\nattribute in Naive Bayes model, because other attributes have the\r\noverlap value between positive and negative virus test. This overlap\r\ncould also be seen in boxplot that shows the negative and positive virus\r\ntest. Second, an employee with the temperature of 99 degrees is\r\nconsidered to have the virus in this analysis. The statistics and the\r\nhistogram above show condition is reasonable. The average temperature of\r\nthis dataset is about 98 degree with standard deviation of 0.9. The\r\nfrequency of employees with positive test begins to obviously increased\r\nat 99 degree, as well as the frequency for negative virus test start to\r\nfall.\r\nFigure 2: Decision tree diagram\r\nrpart.plot(model_pruned)\r\n\r\n\r\n\r\nConclusion\r\nThe pipeline for periodic analysis of employee medical data is built\r\nby cleaning the data, building models, predicting test data, and\r\ncalculating the models’ accuracy. The results show that all the models\r\nhave accuracy at approximately 0.8, ANN has the extremely high leaning\r\ntime, and the decision tree uses the least time for the prediction.\r\nThus, the most effective classification technique in this analysis is a\r\ndecision tree with three variables. This is because of its overall\r\nperformance, simple visualization, and straightforward interpretation.\r\nMoreover, the three variable decision tree is almost as effective as\r\nthose complex models with many variables. However, the results are\r\ndifferent depending on the method used to identify outliers. This model\r\ncould be helpful in primary screening employees with the risk of having\r\nthe virus and preventing the virus from spreading through the\r\nworkplace.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-12-28T17:38:29-05:00"
    }
  ],
  "collections": []
}
